# -*- coding: utf-8 -*-
"""ANN_LABTASK_13_MaryamArshad_FeaturePyramidNetwork_RESNET18.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pv-OyXCdnk8m-1pRYB0Rih0FWd0i4nCG

#Imports
"""

import os
os.environ["CUDA_LAUNCH_BLOCKING"] = "1"

import torch
import torch.nn as nn
import torchvision.models as models
from torchvision.ops import FeaturePyramidNetwork

# Set CPU first to test
device = torch.device("cpu")

model = FPN_Segmentation(num_classes=3).to(device)

x = torch.randn(1, 3, 256, 256).to(device)
out = model(x)
print("Output shape:", out.shape)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Move clean model to GPU
model = FPN_Segmentation(num_classes=3).to(device)

# Test with dummy GPU tensor
x = torch.randn(1, 3, 256, 256).to(device)
out = model(x)
print("Output shape on GPU:", out.shape)

# STEP 0: Force CUDA to give useful error info
import os
os.environ["CUDA_LAUNCH_BLOCKING"] = "1"

# STEP 1: Imports
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
from torchvision import transforms
from torchvision.datasets import OxfordIIITPet
from torchvision.ops import FeaturePyramidNetwork
import torchvision.models as models
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device:", device)

"""# STEP 2: Dataset + Label Remap"""

# Image transform
transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.ToTensor()
])

# Mask transform with label remapping: 1=pet, 2=outline, 3=background → 1=pet, 2=outline, 0=background
def mask_transform(mask):
    mask = transforms.Resize((256, 256), interpolation=Image.NEAREST)(mask)
    mask = transforms.PILToTensor()(mask).squeeze(0)
    # Reassign labels: 3 → 0
    mask[mask == 3] = 0
    return mask.unsqueeze(0)

"""# STEP 3: Load Dataset"""

train_dataset = OxfordIIITPet(
    root="./data",
    download=True,
    transform=transform,
    target_transform=mask_transform,
    target_types="segmentation"
)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)

"""#Add a decode_segmap() Function"""

import numpy as np

def decode_segmap(mask):
    """Convert class indices to RGB color map."""
    label_colors = np.array([
        [0, 0, 0],       # class 0: background (black)
        [128, 0, 0],     # class 1: pet (dark red)
        [0, 128, 0]      # class 2: outline (green)
    ])

    r = label_colors[mask, 0]
    g = label_colors[mask, 1]
    b = label_colors[mask, 2]

    return np.stack([r, g, b], axis=2)

"""#Visualize Dataset Samples"""

import matplotlib.pyplot as plt

def visualize_dataset_sample(dataset, index=0):
    image, mask = dataset[index]

    image = image.permute(1, 2, 0).numpy()  # CHW → HWC
    mask = mask.squeeze(0).numpy()         # [1, H, W] → [H, W]
    decoded_mask = decode_segmap(mask)

    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    axs[0].imshow(image)
    axs[0].set_title("Original Image")
    axs[0].axis("off")

    axs[1].imshow(decoded_mask)
    axs[1].set_title("Segmentation Mask")
    axs[1].axis("off")

    axs[2].imshow(image)
    axs[2].imshow(decoded_mask, alpha=0.5)
    axs[2].set_title("Overlay")
    axs[2].axis("off")

    plt.tight_layout()
    plt.show()

"""#Call It"""

visualize_dataset_sample(train_dataset, index=0)
visualize_dataset_sample(train_dataset, index=10)

"""# STEP 4: FPN Model Definition"""

class FPN_Segmentation(nn.Module):
    def __init__(self, num_classes=3):
        super(FPN_Segmentation, self).__init__()
        resnet = models.resnet18(pretrained=True)
        self.layer0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool)
        self.layer1 = resnet.layer1
        self.layer2 = resnet.layer2
        self.layer3 = resnet.layer3
        self.layer4 = resnet.layer4

        self.fpn = FeaturePyramidNetwork(
            in_channels_list=[64, 128, 256, 512],
            out_channels=256
        )
        self.head = nn.Conv2d(256, num_classes, kernel_size=1)

    def forward(self, x):
        c1 = self.layer0(x)
        c2 = self.layer1(c1)
        c3 = self.layer2(c2)
        c4 = self.layer3(c3)
        c5 = self.layer4(c4)

        features = {'0': c2, '1': c3, '2': c4, '3': c5}
        fpn_out = self.fpn(features)
        out = self.head(fpn_out['0'])
        out = F.interpolate(out, size=x.shape[2:], mode='bilinear', align_corners=False)
        return out

import os
os.environ["CUDA_LAUNCH_BLOCKING"] = "1"

model = FPN_Segmentation(num_classes=3).to("cpu")
x = torch.randn(1, 3, 256, 256)
out = model(x)
print(out.shape)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = FPN_Segmentation(num_classes=3).to(device)

"""#STEP 5: Init Model, Loss, Optimizer"""

model = FPN_Segmentation(num_classes=3).to(device)
criterion = nn.CrossEntropyLoss(ignore_index=2)  # ignore outline
optimizer = optim.Adam(model.parameters(), lr=0.001)

"""# STEP 6: Training Function"""

def train_one_epoch(model, loader):
    model.train()
    total_loss, correct, total = 0, 0, 0

    for images, masks in tqdm(loader, desc="Training"):
        images = images.to(device)
        masks = masks.squeeze(1).long().to(device)  # [B, H, W]

        outputs = model(images)
        loss = criterion(outputs, masks)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        preds = outputs.argmax(1)
        correct += (preds == masks).sum().item()
        total += masks.numel()

    return total_loss / len(loader), correct / total

"""#STEP 7: Train the Model"""

for epoch in range(50):  # Keep it short for demo
    loss, acc = train_one_epoch(model, train_loader)
    print(f"Epoch {epoch+1}/5 - Loss: {loss:.4f} | Pixel Acc: {acc:.4f}")

plt.figure(figsize=(7,4))
plt.plot(range(1, len(accuracies)+1), accuracies, color='orange')
plt.title('Pixel Accuracy over Epochs')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.grid(True)
plt.tight_layout()
plt.show()

"""#STEP 8: Visualize Predictions


"""

def decode_segmap(mask):
    colors = np.array([[0, 0, 0], [128, 0, 0], [0, 128, 0]])  # background, pet, outline
    r = colors[mask, 0]
    g = colors[mask, 1]
    b = colors[mask, 2]
    return np.stack([r, g, b], axis=2)

def visualize_sample(model, dataset, idx=0):
    model.eval()
    img, mask = dataset[idx]
    with torch.no_grad():
        pred = model(img.unsqueeze(0).to(device))
        pred = torch.argmax(pred, dim=1).squeeze(0).cpu().numpy()

    fig, axs = plt.subplots(1, 3, figsize=(15, 5))
    axs[0].imshow(img.permute(1, 2, 0).numpy())
    axs[0].set_title("Image")
    axs[1].imshow(decode_segmap(mask.squeeze(0).numpy()))
    axs[1].set_title("Ground Truth")
    axs[2].imshow(decode_segmap(pred))
    axs[2].set_title("Prediction")
    for ax in axs:
        ax.axis('off')
    plt.tight_layout()
    plt.show()

visualize_sample(model, train_dataset, idx=5)

"""#STEP 9: Save Model"""

torch.save(model.state_dict(), "fpn_pet_segmentation.pth")